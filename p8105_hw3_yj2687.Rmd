---
title: "p8105_hw3_yj2687"
author: "Yijia Jiang"
date: "2022-10-07"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```




## Problem 1 (Instacart dataset)
```{r,warning = FALSE,message=FALSE}
data("instacart")

instacart_df = 
  instacart %>% 
  as_tibble(instacart)

instacart_df %>% 
  count(aisle) %>% 
  arrange(desc(n))

instacart_df %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()

instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = mean_hour) %>%
  knitr::kable(digits = 2)
```

&nbsp;

## Problem 2 (Accelerometer dataset)
```{r,warning = FALSE,message=FALSE}
# Tidy the dataset
accel_df = read.csv("./p8105_hw3_data/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(activity_1:activity_1440, names_to = "minutes_in_a_day", 
               names_prefix = "activity_", values_to = "activity_count") %>% 
  mutate(weekday_vs_weekend = case_when(
    day == "Monday"  ~ "Weekday",
    day == "Tuesday"  ~ "Weekday",
    day == "Wednesday"  ~ "Weekday",
    day == "Thursday"  ~ "Weekday",
    day == "Friday"  ~ "Weekday",
    day == "Sunday"  ~ "Weekend",
    day == "Saturday"  ~ "Weekend"
  )) %>% 
  select(week, day_id, day, weekday_vs_weekend, everything()) %>% 
  mutate_if(is.double, as.integer) %>%
  mutate(minutes_in_a_day = as.integer(minutes_in_a_day))
```

* There are `r nrow(accel_df)` observations in the resulting tidy dataset, including `r ncol(accel_df)` variables, namely `r names(accel_df)`.



```{r}
# Create a table showing total activity for each day by aggregating across minutes
accel_df$day = factor(accel_df$day, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))

accel_df %>% 
  group_by(day) %>% 
  summarize(total = sum(activity_count)) %>% 
  knitr::kable(align = "l", format = "pipe", col.names = c("Day","Total"))

```


* It is difficult to identify the apparent trends across days according to this table, while we can see the total activity on Saturdays is much lower than that on other days and Friday has the highest total activity.


```{r}
# Make a single-panel plot showing the 24-hour activity time courses for each day and use color to indicate day of the week. 
accel_df %>% 
  group_by(day, minutes_in_a_day) %>%
  rename(Day = day) %>%
  ggplot(aes(minutes_in_a_day, activity_count, color = Day)) +
  geom_point(alpha = 0.5) +
  scale_x_continuous(
    breaks = c(0, 180, 360, 540, 720, 900, 1080, 1260, 1440),
    labels = c("12AM", "3AM", "6AM", "9AM", "12PM", "3PM", "6PM", "9PM", "11:59PM")) + 
  labs(
    title = "24-hour activity time courses for each day",
    x = "Time",
    y = "Activity Count") +
  theme(legend.position = "right")
```

* We can see that most of the activity count for every minute throughout the day is usually below 2500. The activity count at noon and evenings tends to peak compared to the other time of the day. 

&nbsp;


## Problem 3 (NY NOAA dataset)
```{r,warning = FALSE,message=FALSE}
# Tidy the dataset
noaa_df = ny_noaa %>% 
  janitor::clean_names() %>%
  separate(date, into = c("year", "month", "day"), convert = TRUE) %>% 
  arrange(year, month) %>%
  mutate(prcp = prcp/10,
         tmax = (as.double(tmax)/10),
         tmin = (as.double(tmin)/10)) 

# Count the most commonly values for snowfall
snow_obs = noaa_df %>%
  count(snow) %>% 
  arrange(desc(n))
```

* This data collected weather data from all New York state weather stations between `r noaa_df %>% pull(year) %>% min()` and `r noaa_df %>% pull(year) %>% max()`.
* There are `r nrow(noaa_df)` observations in the resulting tidied dataset, including `r ncol(noaa_df)` variables, namely `r names(noaa_df)`.
* The `id` is a `r class(noaa_df$id)` variable, the `year`, `month`, `day` are `r class(noaa_df$year)` variables, and `prcp`, `snow`, `snwd`, `tmax`, `tmin` are `r class(noaa_df$prcp)` variables.
* Interestingly, before tidy procedure, the variables `tmax` and `tmin` were defined as a character, the `snow` variable has a negative value of -13mm.
* There exist `r sum(is.na(noaa_df$prcp))` missing values in `prcp`, `r sum(is.na(noaa_df$snow))` missing values in `snow`, `r sum(is.na(noaa_df$snwd))` missing values in `snwd`, `r sum(is.na(noaa_df$tmax))` missing values in `tmax` and `r sum(is.na(noaa_df$tmin))` missing values in `tmin`.
* For snowfall, the most commonly observed value is `r snow_obs[1,1]` mm.

